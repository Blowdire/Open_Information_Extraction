{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, coreferee\n",
    "from spacy.matcher import Matcher\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coreferee.manager.CorefereeBroker at 0x1e02a3a7e20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.max_length = 3200000\n",
    "nlp.add_pipe('coreferee')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def import_file(file_name):\n",
    "  text = \"\"\n",
    "\n",
    "\n",
    "  with open(file_name, encoding=\"utf8\") as f:\n",
    "    try:\n",
    "      text = f.readlines()\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "\n",
    "\n",
    "\n",
    "  string_text = \"\"\n",
    "  for line in text:\n",
    "    string_text += line + \"\\n\"\n",
    "  string_text = re.sub('[\\n]+', '\\n', string_text)\n",
    "  return string_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"LOTRC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "textString = import_file(\"./Datasets/\"+filename+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE LORD\\nOF THE RINGS\\nChapter 1\\nA LONG-EXPECTED PARTY\\nWhen Mr. Bilbo Baggins of Bag End announced that he would shortly be celebrating his eleventy-first birthday with a party of special magnificence, there was much talk and excitement in Hobbiton.\\nBilbo was very rich and very peculiar, and had been the wonder of the Shire for sixty years, ever since his remarkable disappearance and unexpected return. The riches he had brought back from his travels had now become a local legend, and it was popularly believed, whatever the old folk might say, that the Hill at Bag End was full of tunnels stuffed with treasure. And if that was not enough for fame, there was also his prolonged vigour to marvel at. Time wore on, but it seemed to have little effect on Mr. Baggins. At ninety he was much the same as at fifty. At ninety-nine they began to call him well-preserved; but unchanged would have been nearer the mark. There were some that shook their heads and thought this was too much of a good thing; '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textString[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(textString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(doc, open(\"./Dumps/LOTR/LOTRC_spacy.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreference_resolved = \"\"\n",
    "for document in doc:\n",
    "  res = doc._.coref_chains.resolve(document)\n",
    "  coreference_resolved += res[0].text +\" \" if res else document.text + \" \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Datasets/\"+filename+\"_COREF.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "  f.write(coreference_resolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = coreference_resolved[:500].split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "textString = import_file(\"./Datasets/\"+filename+\"_COREF.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n Chapter 1 \\n A LONG - EXPECTED PARTY \\n When Mr. Bilbo Baggins of Bag End announced that Baggins wou'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textString[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(coreference_resolved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pickle.load(open(\"./Dumps/LOTR/\"+filename+\"_COREF_spacy.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(doc, open(\"./Dumps/LOTR/\"+filename+\"_COREF_spacy.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDoc = doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [\n",
    "    #First Pattern\n",
    "    [{\"POS\": {\"IN\": [\"PROPN\"]}, \"OP\":\"*\"}, {\"POS\": {\"IN\": [\"PROPN\"]}, \"OP\":\"+\"}, \n",
    "    {\"POS\": \"VERB\"},     {\"POS\": \"PART\", \"OP\": \"*\"}, \n",
    "    {\"POS\": \"ADV\", \"OP\": \"*\"}, {\"POS\": {\"IN\": [\"PROPN\"]}, \"OP\": \"+\"},\n",
    "    {\"POS\": {\"IN\": [\"PROPN\", \"NOUN\"]}, \"OP\":\"*\"}],\n",
    "    #Second pattern\n",
    "    [{\"POS\": {\"IN\": [\"PROPN\"]}, \"OP\":\"*\"},\n",
    "    {\"POS\": {\"IN\": [\"PROPN\"]}, \"OP\":\"+\"}, {\"POS\": \"VERB\"},\n",
    "     {\"POS\": {\"IN\": [\"PART\", \"ADV\", \"CONJ\"]}, \"OP\": \"*\"},  \n",
    "     {\"POS\": {\"IN\": [ \"ADV\"]}, \"OP\": \"+\"},\n",
    "     {\"POS\": {\"IN\": [\"PROPN\", \"NOUN\"]}, \"OP\":\"+\"}],\n",
    "    #Third pattern\n",
    "    [{\"POS\": {\"IN\": [\"PROPN\"]}, \"OP\":\"*\"},\n",
    "    {\"POS\": {\"IN\": [\"PROPN\"]}, \"OP\":\"+\"}, {\"POS\": \"VERB\"},\n",
    "     {\"POS\": {\"IN\": [\"PART\", \"ADV\", \"CONJ\"]}, \"OP\": \"*\"}, \n",
    "     {\"POS\": {\"IN\": [\"ADV\"]}, \"OP\": \"+\"}, \n",
    "     {\"POS\": {\"IN\": [\"PROPN\", ]}, \"OP\":\"+\"}, \n",
    "     {\"POS\": {\"IN\": [\"PART\", \"ADV\", \"CONJ\", \"ADJ\", \"VERB\"]}, \"OP\": \"*\"},  \n",
    "     {\"POS\": {\"IN\": [\"PROPN\", \"NOUN\"]}, \"OP\":\"+\"}]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try matching dependency tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"initial\",pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(newDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_string_array(array):\n",
    "    longest_string = \"\"\n",
    "    for string in array:\n",
    "        if len(string) > len(longest_string):\n",
    "            longest_string = string\n",
    "    return longest_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(columns=[\"Rel\",\"End\"])\n",
    "filteredarray = []\n",
    "otherArray = []\n",
    "for match in matches:\n",
    "  start = match[1]\n",
    "  end = match[2]\n",
    "  tempArray = []\n",
    "  for new_match in matches:\n",
    "    if new_match[1] == start or new_match[2] == end:\n",
    "      tempArray.append(newDoc[new_match[1]:new_match[2]])\n",
    "  if len(tempArray) > 1:\n",
    "    sentence = longest_string_array(tempArray)\n",
    "\n",
    "    if sentence.text != \"\" and sentence not in filteredarray:\n",
    "      filteredarray.append(sentence)\n",
    "  else:\n",
    "    filteredarray.append(newDoc[start:end])\n",
    "    test_df.loc[len(test_df)] = [newDoc[start:end], newDoc[end].i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.sort_values(by=\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = pd.DataFrame(columns=[\"ENTITY1\", \"RELATION\", \"ENTITY2\",\"ADDITIONAL\"])\n",
    "for relation in filteredarray:\n",
    "  processed_relation = nlp(relation.text)\n",
    "  i = 0\n",
    "  entities = [False, False]\n",
    "  relation = \"\"\n",
    "  additional=\"\"\n",
    "  while i < len(processed_relation):\n",
    "   \n",
    "    prev_token = processed_relation[i-1] if i > 0 else None\n",
    "    token = processed_relation[i]\n",
    "    entity_name = \"\"\n",
    "    if token.pos_ == \"PROPN\" or token.pos_ == \"NOUN\":\n",
    "      \n",
    "      entity_name += token.text\n",
    "      j = i+1\n",
    "      while j <len(processed_relation) and (processed_relation[j].pos_ == \"PROPN\" or processed_relation[j].pos_ == \"NOUN\"):\n",
    "        entity_name += \" \" + processed_relation[j].text\n",
    "        j += 1\n",
    "      i = j-1\n",
    "      if \"subj\" in processed_relation[i].dep_ and i < len(processed_relation):\n",
    "        entities[0] = entity_name\n",
    "      elif \"obj\" in processed_relation[i].dep_ and i < len(processed_relation):\n",
    "        splitted = entity_name.split(\" \")\n",
    "\n",
    "        if len(splitted) > 1 and processed_relation[i].pos_ == \"NOUN\":\n",
    "          entity_name = \" \".join(splitted[:len(splitted)-1])\n",
    "          additional = \" \".join(splitted[len(splitted)-1:])\n",
    "    \n",
    "   \n",
    "        \n",
    "        entities[1] = entity_name\n",
    "      \n",
    "      \n",
    "    else:\n",
    "      relation +=\" \"+ token.text\n",
    "    \n",
    "    i+=1\n",
    "  if len(entities) == 2 and entities[0] != False and entities[1] != False:\n",
    "    splitted_second = entities[1].split(\" \")\n",
    "    if len(splitted_second) > 1 and entities[0] == splitted_second[0]:\n",
    "      if entities[0] != entities[1]:\n",
    "        triples.loc[len(triples)] = [entities[0], relation,\n",
    "                                   entities[1],additional]\n",
    "    else:\n",
    "      if entities[0] != entities[1]:\n",
    "        triples.loc[len(triples)] = [entities[0], relation, entities[1],additional]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19216/1032015148.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./word2vec-google-news-300.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ruben\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loaded\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ruben\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \"\"\"\n\u001b[0;32m   1460\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from collections.abc import Mapping\n",
    "model = KeyedVectors.load('./word2vec-google-news-300.model')\n",
    "model.vectors[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "def simple_preproc(text):\n",
    "  \"\"\"\n",
    "  see: https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\n",
    "  \"\"\"\n",
    "  return text.translate(str.maketrans('', '', string.punctuation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Datasets/\"+filename+'_COREF.txt', encoding=\"utf8\") as read_file:\n",
    "  sentences = [simple_preproc(k).lower().split()\n",
    "               for k in read_file.readlines()]\n",
    "model = Word2Vec(sentences=sentences, vector_size=100,\n",
    "                 window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_errors = 0\n",
    "triples_vec = pd.DataFrame(columns=[\"ENTITY1\", \"RELATION\", \"ENTITY2\",\"ADDITIONAL\",\"VECTOR\"])\n",
    "for index, row in triples.iterrows():\n",
    "  try:\n",
    "    vectors=[]\n",
    "    for word in row[1].split(\" \"):\n",
    "      if word != '':\n",
    "        vector = model.wv[word.strip()]\n",
    "        vectors.append(vector)\n",
    "    triples_vec.loc[len(triples_vec)] = [\n",
    "        row[0], row[1], row[2], row[3], vectors]\n",
    "  except Exception as e:\n",
    "    num_errors +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTITY1</th>\n",
       "      <th>RELATION</th>\n",
       "      <th>ENTITY2</th>\n",
       "      <th>ADDITIONAL</th>\n",
       "      <th>VECTOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bilbo</td>\n",
       "      <td>adopted</td>\n",
       "      <td>Frodo</td>\n",
       "      <td></td>\n",
       "      <td>[[-0.04841782, 0.076585054, 0.06452375, -0.039...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Otho</td>\n",
       "      <td>disliked</td>\n",
       "      <td>Bilbo</td>\n",
       "      <td></td>\n",
       "      <td>[[-0.014119601, 0.029947247, 0.011427209, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Old Odo Proudfoot</td>\n",
       "      <td>removed</td>\n",
       "      <td>Bilbo</td>\n",
       "      <td>feet</td>\n",
       "      <td>[[-0.1541097, 0.23161198, 0.22655354, -0.06067...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Old Odo Proudfoot</td>\n",
       "      <td>removed</td>\n",
       "      <td>Bilbo</td>\n",
       "      <td></td>\n",
       "      <td>[[-0.1541097, 0.23161198, 0.22655354, -0.06067...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frodo</td>\n",
       "      <td>escorted</td>\n",
       "      <td>Lobelia</td>\n",
       "      <td></td>\n",
       "      <td>[[-0.012109284, 0.01570673, 0.016003642, 0.002...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ENTITY1   RELATION  ENTITY2 ADDITIONAL  \\\n",
       "0              Bilbo    adopted    Frodo              \n",
       "1               Otho   disliked    Bilbo              \n",
       "2  Old Odo Proudfoot    removed    Bilbo       feet   \n",
       "3  Old Odo Proudfoot    removed    Bilbo              \n",
       "4              Frodo   escorted  Lobelia              \n",
       "\n",
       "                                              VECTOR  \n",
       "0  [[-0.04841782, 0.076585054, 0.06452375, -0.039...  \n",
       "1  [[-0.014119601, 0.029947247, 0.011427209, -0.0...  \n",
       "2  [[-0.1541097, 0.23161198, 0.22655354, -0.06067...  \n",
       "3  [[-0.1541097, 0.23161198, 0.22655354, -0.06067...  \n",
       "4  [[-0.012109284, 0.01570673, 0.016003642, 0.002...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTITY1</th>\n",
       "      <th>RELATION</th>\n",
       "      <th>ENTITY2</th>\n",
       "      <th>ADDITIONAL</th>\n",
       "      <th>VECTOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bilbo</td>\n",
       "      <td>adopted</td>\n",
       "      <td>Frodo</td>\n",
       "      <td></td>\n",
       "      <td>[-0.04841782, 0.076585054, 0.06452375, -0.0392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Otho</td>\n",
       "      <td>disliked</td>\n",
       "      <td>Bilbo</td>\n",
       "      <td></td>\n",
       "      <td>[-0.014119601, 0.029947247, 0.011427209, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Old Odo Proudfoot</td>\n",
       "      <td>removed</td>\n",
       "      <td>Bilbo</td>\n",
       "      <td>feet</td>\n",
       "      <td>[-0.1541097, 0.23161198, 0.22655354, -0.060672...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Old Odo Proudfoot</td>\n",
       "      <td>removed</td>\n",
       "      <td>Bilbo</td>\n",
       "      <td></td>\n",
       "      <td>[-0.1541097, 0.23161198, 0.22655354, -0.060672...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frodo</td>\n",
       "      <td>escorted</td>\n",
       "      <td>Lobelia</td>\n",
       "      <td></td>\n",
       "      <td>[-0.012109284, 0.01570673, 0.016003642, 0.0024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frodo</td>\n",
       "      <td>saw</td>\n",
       "      <td>Gandalf</td>\n",
       "      <td></td>\n",
       "      <td>[0.08047636, -0.36959633, 0.8828216, 0.4029530...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gandalf</td>\n",
       "      <td>paid</td>\n",
       "      <td>Frodo</td>\n",
       "      <td></td>\n",
       "      <td>[-0.01753119, 0.15533338, 0.044456325, -0.0911...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Frodo</td>\n",
       "      <td>welcomed</td>\n",
       "      <td>Sam</td>\n",
       "      <td></td>\n",
       "      <td>[-0.04632163, 0.09652247, 0.057476882, -0.0269...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sam</td>\n",
       "      <td>pressed</td>\n",
       "      <td>Gandalf</td>\n",
       "      <td></td>\n",
       "      <td>[-0.05358205, 0.13839875, 0.13058482, 0.041677...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Orcs</td>\n",
       "      <td>saw</td>\n",
       "      <td>Isildur</td>\n",
       "      <td></td>\n",
       "      <td>[0.08047636, -0.36959633, 0.8828216, 0.4029530...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sméagol</td>\n",
       "      <td>caught</td>\n",
       "      <td>Déagol</td>\n",
       "      <td></td>\n",
       "      <td>[-0.18805967, 0.30405623, 0.42326617, -0.18085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gollum</td>\n",
       "      <td>hated</td>\n",
       "      <td>Ring</td>\n",
       "      <td></td>\n",
       "      <td>[-0.04054272, 0.07159067, 0.060652766, -0.0647...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gollum</td>\n",
       "      <td>hated</td>\n",
       "      <td>Ring</td>\n",
       "      <td></td>\n",
       "      <td>[-0.04054272, 0.07159067, 0.060652766, -0.0647...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ring</td>\n",
       "      <td>left</td>\n",
       "      <td>Bilbo</td>\n",
       "      <td></td>\n",
       "      <td>[0.07715502, 0.62549984, 0.6201461, -0.1503961...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ring</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>Gollum</td>\n",
       "      <td></td>\n",
       "      <td>[-0.02497287, 0.035716776, 0.02518893, -0.0278...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Déagol</td>\n",
       "      <td>haunted</td>\n",
       "      <td>Gollum</td>\n",
       "      <td></td>\n",
       "      <td>[-0.11715794, 0.010804073, 0.14316283, 0.07153...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gollum</td>\n",
       "      <td>hated</td>\n",
       "      <td>Bilbo</td>\n",
       "      <td></td>\n",
       "      <td>[-0.04054272, 0.07159067, 0.060652766, -0.0647...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sam Baggins</td>\n",
       "      <td>pretended</td>\n",
       "      <td>Baggins</td>\n",
       "      <td></td>\n",
       "      <td>[0.031450853, 0.040609438, -0.0293882, -0.0204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gandalf</td>\n",
       "      <td>wanted</td>\n",
       "      <td>Frodo</td>\n",
       "      <td></td>\n",
       "      <td>[0.006957297, 0.38748866, -0.07407345, -0.2777...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sam</td>\n",
       "      <td>shouldered</td>\n",
       "      <td>Frodo</td>\n",
       "      <td>packs</td>\n",
       "      <td>[-0.009876297, 0.013363499, 0.009890421, -0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ENTITY1     RELATION  ENTITY2 ADDITIONAL  \\\n",
       "0               Bilbo      adopted    Frodo              \n",
       "1                Otho     disliked    Bilbo              \n",
       "2   Old Odo Proudfoot      removed    Bilbo       feet   \n",
       "3   Old Odo Proudfoot      removed    Bilbo              \n",
       "4               Frodo     escorted  Lobelia              \n",
       "5               Frodo          saw  Gandalf              \n",
       "6             Gandalf         paid    Frodo              \n",
       "7               Frodo     welcomed      Sam              \n",
       "8                 Sam      pressed  Gandalf              \n",
       "9                Orcs          saw  Isildur              \n",
       "10            Sméagol       caught   Déagol              \n",
       "11             Gollum        hated     Ring              \n",
       "12             Gollum        hated     Ring              \n",
       "13               Ring         left    Bilbo              \n",
       "14               Ring    abandoned   Gollum              \n",
       "15             Déagol      haunted   Gollum              \n",
       "16             Gollum        hated    Bilbo              \n",
       "17        Sam Baggins    pretended  Baggins              \n",
       "18            Gandalf       wanted    Frodo              \n",
       "19                Sam   shouldered    Frodo      packs   \n",
       "\n",
       "                                               VECTOR  \n",
       "0   [-0.04841782, 0.076585054, 0.06452375, -0.0392...  \n",
       "1   [-0.014119601, 0.029947247, 0.011427209, -0.00...  \n",
       "2   [-0.1541097, 0.23161198, 0.22655354, -0.060672...  \n",
       "3   [-0.1541097, 0.23161198, 0.22655354, -0.060672...  \n",
       "4   [-0.012109284, 0.01570673, 0.016003642, 0.0024...  \n",
       "5   [0.08047636, -0.36959633, 0.8828216, 0.4029530...  \n",
       "6   [-0.01753119, 0.15533338, 0.044456325, -0.0911...  \n",
       "7   [-0.04632163, 0.09652247, 0.057476882, -0.0269...  \n",
       "8   [-0.05358205, 0.13839875, 0.13058482, 0.041677...  \n",
       "9   [0.08047636, -0.36959633, 0.8828216, 0.4029530...  \n",
       "10  [-0.18805967, 0.30405623, 0.42326617, -0.18085...  \n",
       "11  [-0.04054272, 0.07159067, 0.060652766, -0.0647...  \n",
       "12  [-0.04054272, 0.07159067, 0.060652766, -0.0647...  \n",
       "13  [0.07715502, 0.62549984, 0.6201461, -0.1503961...  \n",
       "14  [-0.02497287, 0.035716776, 0.02518893, -0.0278...  \n",
       "15  [-0.11715794, 0.010804073, 0.14316283, 0.07153...  \n",
       "16  [-0.04054272, 0.07159067, 0.060652766, -0.0647...  \n",
       "17  [0.031450853, 0.040609438, -0.0293882, -0.0204...  \n",
       "18  [0.006957297, 0.38748866, -0.07407345, -0.2777...  \n",
       "19  [-0.009876297, 0.013363499, 0.009890421, -0.01...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "temp_dataset = triples_vec\n",
    "for index, row in triples_vec.iterrows():\n",
    "  vectors = row[4]\n",
    "  if len(vectors) > 1:\n",
    "    average = np.mean(vectors, axis=0)\n",
    "    temp_dataset.loc[index][\"VECTOR\"] = average\n",
    "    \n",
    "  else:\n",
    "    temp_dataset.loc[index][\"VECTOR\"] = row[4][0]\n",
    "temp_dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN  # To instantiate and fit the model\n",
    "from sklearn.metrics import pairwise_distances  # For Model evaluation\n",
    "from sklearn.neighbors import NearestNeighbors  # For Hyperparameter Tuning\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN(eps=0.05, min_samples=2).fit(temp_dataset[\"VECTOR\"].values.tolist())  # fitting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = set(dbscan.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dataset[\"LABEL\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in temp_dataset.iterrows():\n",
    "  temp_dataset.loc[index,\"LABEL\"] = dbscan.labels_[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for label in unique:\n",
    "  current_label_items = temp_dataset.loc[temp_dataset[\"LABEL\"] == label]\n",
    "  relations = current_label_items[\"RELATION\"].values\n",
    "  average = np.mean(current_label_items[\"VECTOR\"].values, axis=0)\n",
    "  new_selected_relation = model.wv.most_similar(average)\n",
    "  # print(model.wv.most_similar(average)[0][0])\n",
    "  temp_dataset.loc[temp_dataset[\"LABEL\"] == label,\n",
    "                   \"NEW_RELATION\"] = new_selected_relation[0][0]\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dataset.to_csv(\"./Datasets/\"+filename+\"_TRIPLES.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e850eec08e9669c52e782ee28b71a07544c9e38f5af88e96f29f06e82864309f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
